\BOOKMARK [1][-]{section.1}{Introduction}{}% 1
\BOOKMARK [1][-]{section.2}{Method}{}% 2
\BOOKMARK [2][-]{subsection.2.1}{RL environment definition}{section.2}% 3
\BOOKMARK [2][-]{subsection.2.2}{-greedy algorithm}{section.2}% 4
\BOOKMARK [2][-]{subsection.2.3}{Q learning algorithm}{section.2}% 5
\BOOKMARK [2][-]{subsection.2.4}{Weighted sum for action selection}{section.2}% 6
\BOOKMARK [1][-]{section.3}{Modules}{}% 7
\BOOKMARK [2][-]{subsection.3.1}{Forward module}{section.3}% 8
\BOOKMARK [2][-]{subsection.3.2}{Sidewalk module}{section.3}% 9
\BOOKMARK [2][-]{subsection.3.3}{Litter module}{section.3}% 10
\BOOKMARK [2][-]{subsection.3.4}{Obstacle module}{section.3}% 11
\BOOKMARK [1][-]{section.4}{Results}{}% 12
\BOOKMARK [2][-]{subsection.4.1}{Training modules}{section.4}% 13
\BOOKMARK [2][-]{subsection.4.2}{Evaluation of each module}{section.4}% 14
\BOOKMARK [2][-]{subsection.4.3}{Evaluation of the final module}{section.4}% 15
\BOOKMARK [1][-]{section.5}{Summary}{}% 16
